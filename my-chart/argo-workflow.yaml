apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: spark-pipeline-workflow
spec:
  entrypoint: main-pipeline
  volumes:
    - name: spark-storage
      persistentVolumeClaim:
        claimName: spark-data-pvc
    - name: config-volume
      configMap:
        name: app-config
  templates:

    - name: main-pipeline
      dag:
        tasks:
          - name: data-ingestion
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: ingestion_pipeline.py

          - name: data-validation
            dependencies: [data-ingestion]
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: validation_pipeline.py


          - name: data-transformation
            dependencies: [data-validation]
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: transformation_pipeline.py

          - name: model-training
            dependencies: [data-transformation]
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: training_pipeline.py

          - name: model-evaluation
            dependencies: [model-training]
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: evaluation_pipeline.py

          - name: model-push
            dependencies: [model-evaluation]
            template: run-stage
            arguments:
              parameters:
                - name: training-script
                  value: pusher_pipeline.py

    - name: run-stage
      inputs:
        parameters:
          - name: training-script
      container:
        image: mypyspark:latest
        imagePullPolicy: Never
        command: [sh, -c]
        args:
          - |
            set -x
            /opt/venv/bin/python -m pip install --no-cache-dir pandas numpy google-cloud-storage==3.0.0 pyodbc python-dotenv tqdm pyarrow \
              venv-pack pymongo flask watchdog requests kafka-python confluent-kafka PyYAML && \
            /opt/venv/bin/python /app/{{inputs.parameters.training-script}}
        volumeMounts:
          - name: spark-storage
            mountPath: /app/artifact
          - name: config-volume
            mountPath: /app/config