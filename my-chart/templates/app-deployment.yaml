apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-python-app
  labels:
    app: my-python-app
spec:
  serviceName: my-python-app-headless 
  selector:
    matchLabels:
      app: my-python-app
  template:
    metadata:
      labels:
        app: my-python-app
    spec:
      serviceAccountName: spark
      containers:
        - name: my-python-app
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: Never
          ports:
            - containerPort: 4040
              name: spark-ui
            - containerPort: 7078
              name: spark-driver
            - containerPort: 5000
              name: flask-ui
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /
              port: 4040
            initialDelaySeconds: 20
            periodSeconds: 5
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /
              port: 4040
            initialDelaySeconds: 30
            periodSeconds: 10
          env:
            - name: PYSPARK_PYTHON
              value: /opt/venv/bin/python
            - name: PYTHONUNBUFFERED
              value: "1"
            - name: JAVA_HOME
              value: "/opt/java/openjdk"
            - name: HADOOP_HOME
              value: "/opt/hadoop"
            - name: HADOOP_CONF_DIR
              value: "/opt/hadoop/etc/hadoop"
            - name: SPARK_HOME
              value: "/opt/spark"
            - name: SPARK_LOCAL_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: STARTUP_COMMAND
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: startup-command
            - name: MONGO_DB_URL
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.mongodb.connectionUri.secretName }}
                  key: {{ .Values.mongodb.connectionUri.secretKey }}
            - name: SQL_SERVER_HOST
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.host.secretName }}
                  key: {{ .Values.sqlserver.host.secretKey }}
            - name: SQL_SERVER_PORT
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.port.secretName }}
                  key: {{ .Values.sqlserver.port.secretKey }}
            - name: SQL_SERVER_DATABASE
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.database.secretName }}
                  key: {{ .Values.sqlserver.database.secretKey }}
            - name: SQL_SERVER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.username.secretName }}
                  key: {{ .Values.sqlserver.username.secretKey }}
            - name: SQL_SERVER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.password.secretName }}
                  key: {{ .Values.sqlserver.password.secretKey }}
            - name: SQL_SERVER_TABLE
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sqlserver.table.secretName }}
                  key: {{ .Values.sqlserver.table.secretKey }}
            # Spark Core Configuration   
            - name: SPARK_DRIVER_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SPARK_DRIVER_PORT
              value: "29413"           
            - name: SPARK_UI_PORT
              value: "4040"
            
            #cluster
            - name: SPARK_MASTER
              value: "local[2]"  
            - name: SPARK_APP_NAME
              value: "my-python-app"

            #k8s config
            - name: SPARK_K8S_IMAGE
              value: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
            - name: SPARK_K8S_NAMESPACE
              value: "default"
            - name: SPARK_K8S_SERVICE_ACCOUNT
              value: "{{ .Values.serviceAccount.name }}"
            - name: SPARK_K8S_BATCH_DELAY
              value: "5s"
            
            # Resource Configuration
            - name: SPARK_EXECUTOR_MEMORY
              value: "14g"
            - name: SPARK_DRIVER_MEMORY
              value: "14g"
            - name: SPARK_MEMORY_FRACTION
              value: "0.75"
            - name: SPARK_STORAGE_FRACTION
              value: "0.3"
            
            #PERFORMANCE
            - name: SPARK_SHUFFLE_PARTITIONS
              value: "4"
            - name: SPARK_DEFAULT_PARALLELISM
              value: "4"
            #constants for model versoning  
            - name: MODEL_SAVED_DIR
              value: "{{ .values.model_eval.MODEL_SAVED_DIR}}"
            - name: MODEL_EVALUATION_THRESHOLD_VALUE
              value: "{{ .value.model_eval.MODEL_EVALUATION_THRESHOLD_VALUE}}"
            - name: MODEL_TRAINER_MODEL_NAME
              value: "{{ .value.model_eval.MODEL_TRAINER_MODEL_NAME}}"
            
            - name: MODEL_PUSHER_SAVED_MODEL_DIRS
              value: "{{ .value.model_push.MODEL_PUSHER_SAVED_MODEL_DIRS}}"

            #serialization
            - name: SPARK_SERIALIZER
              value: "org.apache.spark.serializer.KryoSerializer"
            - name: SPARK_KARYO_BUFFER_MAX
              value: "512m"
            
            - name: SPARK_UI_ENABLED
              value: "true"
            - name: SPARK_UI_REVERSE_PROXY
              value: "true"
            
          volumeMounts:
            - name: spark-storage
              mountPath: /app/artifact
            - name: spark-storage
              mountpath: /app/saved_models
            - name: config-volume
              mountPath: /app/config
          resources:
            requests:
              cpu: "0"
              memory: "0Gi"
            limits:
              cpu: "0"
              memory: "0Gi"
          command: ["/bin/sh", "-c"]
          args:
            - $(STARTUP_COMMAND)
      volumes:
        - name: spark-storage
          persistentVolumeClaim:
            claimName: spark-data-pvc
        - name: config-volume
          configMap:
            name: app-config
