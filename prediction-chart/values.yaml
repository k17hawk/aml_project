
replicaCount: 0

image:
  repository: mypyspark
  tag: latest
  pullPolicy: IfNotPresent

sqlserver:
  host:
    secretName: "db-secrets"
    secretKey: "host"  
  port:
    secretName: "db-secrets"
    secretKey: "port"  
  database:
    secretName: "db-secrets"
    secretKey: "database" 
  username:
    secretName: "db-secrets"
    secretKey: "username" 
  password:
    secretName: "db-secrets"
    secretKey: "password" 
  table:
    secretName: "db-secrets"
    secretKey: "table" 

mongodb:
  enabled: true
  auth:
    enabled: false
  architecture: standalone
  replicaCount: 1
  persistence:
    enabled: true
    size: 512Mi  
  resources:
    requests:
      cpu: "100m"    
      memory: "256Mi" 
    limits:
      cpu: "300m"    
      memory: "512Mi" 
  service:
    type: ClusterIP
    port: 27017
  connectionUri:
    secretName: "db-secrets"
    secretKey: "mongodb"

service:
  type: ClusterIP
  port: 80
  targetPort: 5000

serviceAccount:
  create: true  
  name: "spark"

rbac:
  create: true
  roleName: "spark-cluster-role" 
  roleBindingName: "spark-rolebinding"
  namespace: "argo"  

ingress:
  enabled: false

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80

resources:
  requests:
    cpu: "2"       
    memory: "16Gi" 
  limits:
    cpu: "4"       
    memory: "20Gi"   

job:
  restartPolicy: Never
  ttlSecondsAfterFinished: 3600

tolerations: []
nodeSelector: {}
affinity: {}

config:
  enabled: true

workflow:
  enabled: true

server:
  authMode: "server"  
  secure: false 

model_eval:
  theshold_value: 0.02      

dataConsumer:
  persistence:
    enabled: true
    existingClaim: "data-consumer-pvc"  
    mountPath: "/data/inbox-data/"          
    readOnly: true                      

model:
  persistence:
    enabled: true
    existingClaim: "model-pvc"         
    mountPath: "/app/saved_models"         
    readOnly: true                      



