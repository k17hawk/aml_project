{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark_session\n",
    "from pyspark.sql import SparkSession\n",
    "spark_session =  SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .config(\"spark.driver.memory\", \"16g\")\\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .appName('AML_project')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------+----------------+--------+----------------+-----------------+--------------------+----------------------+------------+-------------+--------------------+\n",
      "|    Time|      Date|Sender_account|Receiver_account|  Amount|Payment_currency|Received_currency|Sender_bank_location|Receiver_bank_location|Payment_type|Is_laundering|     Laundering_type|\n",
      "+--------+----------+--------------+----------------+--------+----------------+-----------------+--------------------+----------------------+------------+-------------+--------------------+\n",
      "|10:35:19|2022-10-07|    8724731955|      2769355426| 1459.15|       UK pounds|        UK pounds|                  UK|                    UK|Cash Deposit|            0|Normal_Cash_Deposits|\n",
      "|10:35:20|2022-10-07|    1491989064|      8401255335| 6019.64|       UK pounds|           Dirham|                  UK|                   UAE|Cross-border|            0|      Normal_Fan_Out|\n",
      "|10:35:20|2022-10-07|     287305149|      4404767002|14328.44|       UK pounds|        UK pounds|                  UK|                    UK|      Cheque|            0|Normal_Small_Fan_Out|\n",
      "|10:35:21|2022-10-07|    5376652437|      9600420220| 11895.0|       UK pounds|        UK pounds|                  UK|                    UK|         ACH|            0|       Normal_Fan_In|\n",
      "|10:35:21|2022-10-07|    9614186178|      3803336972|  115.25|       UK pounds|        UK pounds|                  UK|                    UK|Cash Deposit|            0|Normal_Cash_Deposits|\n",
      "|10:35:21|2022-10-07|    8974559268|      3143547511| 5130.99|       UK pounds|        UK pounds|                  UK|                    UK|         ACH|            0|        Normal_Group|\n",
      "|10:35:23|2022-10-07|     980191499|      8577635959|12176.52|       UK pounds|        UK pounds|                  UK|                    UK|         ACH|            0|Normal_Small_Fan_Out|\n",
      "|10:35:23|2022-10-07|    8057793308|      9350896213|    56.9|       UK pounds|        UK pounds|                  UK|                    UK| Credit card|            0|Normal_Small_Fan_Out|\n",
      "|10:35:26|2022-10-07|    6116657264|       656192169| 4738.45|       UK pounds|        UK pounds|                  UK|                    UK|      Cheque|            0|      Normal_Fan_Out|\n",
      "|10:35:29|2022-10-07|    7421451752|      2755709071| 5883.87|    Indian rupee|        UK pounds|                  UK|                    UK| Credit card|            0|      Normal_Fan_Out|\n",
      "|10:35:31|2022-10-07|    5119661534|      9734073275| 2342.31|       UK pounds|        UK pounds|                  UK|                    UK|  Debit card|            0|Normal_Small_Fan_Out|\n",
      "|10:35:34|2022-10-07|    5606024775|      8646193759| 1239.61|       UK pounds|        UK pounds|                  UK|                    UK|Cash Deposit|            0|Normal_Cash_Deposits|\n",
      "|10:35:34|2022-10-07|    1405792399|      5109623450|16555.31|       UK pounds|  Pakistani rupee|                  UK|                    UK| Credit card|            0|       Normal_Fan_In|\n",
      "|10:35:37|2022-10-07|    2188890133|      3938416782|15459.46|       UK pounds|        UK pounds|                  UK|                    UK|      Cheque|            0|Normal_Small_Fan_Out|\n",
      "|10:35:37|2022-10-07|    6715177555|      4460925916|  586.28|       UK pounds|        UK pounds|                  UK|                    UK|      Cheque|            0|Normal_Small_Fan_Out|\n",
      "|10:35:37|2022-10-07|    7017008854|      3714297114| 1971.15|       UK pounds|             Euro|                  UK|                 Spain|Cross-border|            0|Normal_Small_Fan_Out|\n",
      "|10:35:38|2022-10-07|    2047410771|      6646502650| 8110.72|       UK pounds|             Euro|                  UK|                France|Cross-border|            0|       Normal_Fan_In|\n",
      "|10:35:41|2022-10-07|    1470504995|      3347268325|  1190.3|       UK pounds|        UK pounds|                  UK|                    UK| Credit card|            0|        Normal_Group|\n",
      "|10:35:43|2022-10-07|    4473647189|      7892884492|11957.87|       UK pounds|        US dollar|                  UK|                   USA|Cross-border|            0|       Normal_Fan_In|\n",
      "|10:35:44|2022-10-07|    8184612956|      5628674969|10529.75|       UK pounds|        UK pounds|                  UK|                    UK| Credit card|            0|       Normal_Fan_In|\n",
      "+--------+----------+--------------+----------------+--------+----------------+-----------------+--------------------+----------------------+------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark_session.read.csv(\"../Data/SAML-D.csv\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, to_date\n",
    "\n",
    "df = df.withColumn(\"Date\", to_date(df[\"Date\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "df = df.withColumn(\"year\", year(df[\"Date\"])) \\\n",
    "       .withColumn(\"month\", month(df[\"Date\"])) \\\n",
    "       .withColumn(\"day\", dayofmonth(df[\"Date\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp,hour,minute,second \n",
    "\n",
    "df = df.withColumn(\"Time\", to_timestamp(df[\"Time\"], \"HH:mm:ss\"))\n",
    "\n",
    "df = df.withColumn(\"hour\", hour(df[\"Time\"])) \\\n",
    "       .withColumn(\"minute\", minute(df[\"Time\"])) \\\n",
    "       .withColumn(\"second\", second(df[\"Time\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'Date',\n",
       " 'Sender_account',\n",
       " 'Receiver_account',\n",
       " 'Amount',\n",
       " 'Payment_currency',\n",
       " 'Received_currency',\n",
       " 'Sender_bank_location',\n",
       " 'Receiver_bank_location',\n",
       " 'Payment_type',\n",
       " 'Is_laundering',\n",
       " 'Laundering_type',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 7603866 rows\n",
      "Testing Set: 1900986 rows\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Training Set: {train_df.count()} rows\")\n",
    "print(f\"Testing Set: {test_df.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mout\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.limit(603866)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603866"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "numeric_cols = ['Is_laundering']\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    train_df = train_df.withColumn(col_name, col(col_name).cast(\"double\"))\n",
    "    test_df = test_df.withColumn(col_name, col(col_name).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Date', 'Time']\n",
    "train_df = train_df.drop(*drop_cols)\n",
    "test_df = test_df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sender_account',\n",
       " 'Receiver_account',\n",
       " 'Amount',\n",
       " 'Payment_currency',\n",
       " 'Received_currency',\n",
       " 'Sender_bank_location',\n",
       " 'Receiver_bank_location',\n",
       " 'Payment_type',\n",
       " 'Is_laundering',\n",
       " 'Laundering_type',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'minute',\n",
       " 'second']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location',\n",
    "                    'Receiver_bank_location', 'Payment_type', 'Laundering_type']\n",
    "numeric_cols = ['Sender_account', 'Receiver_account', 'Amount', 'year', 'month', 'day', 'hour', 'minute', 'second','Is_laundering']\n",
    "scaled_cols = ['Amount', 'year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "\n",
    "# String Indexing for categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "\n",
    "# Casting numeric columns to double\n",
    "train_df = train_df.select([col(c).cast(\"double\").alias(c) for c in numeric_cols] + categorical_cols)\n",
    "test_df = test_df.select([col(c).cast(\"double\").alias(c) for c in numeric_cols] + categorical_cols)\n",
    "\n",
    "# Handling class imbalance using oversampling\n",
    "fraud_cases = train_df.filter(col(\"Is_laundering\") == 1)\n",
    "non_fraud_cases = train_df.filter(col(\"Is_laundering\") == 0)\n",
    "fraud_count = fraud_cases.count()\n",
    "non_fraud_count = non_fraud_cases.count()\n",
    "\n",
    "if fraud_count < non_fraud_count:\n",
    "    fraud_cases = fraud_cases.sample(withReplacement=True, fraction=non_fraud_count / fraud_count, seed=42)\n",
    "elif non_fraud_count < fraud_count:\n",
    "    non_fraud_cases = non_fraud_cases.sample(withReplacement=True, fraction=fraud_count / non_fraud_count, seed=42)\n",
    "\n",
    "# Ensuring class balance\n",
    "train_df = fraud_cases.union(non_fraud_cases)\n",
    "\n",
    "# Assembling features excluding 'Is_laundering'\n",
    "assembler = VectorAssembler(inputCols=[c for c in numeric_cols if c != 'Is_laundering'] + [c + \"_index\" for c in categorical_cols], outputCol=\"features\")\n",
    "\n",
    "# Scaling numeric columns\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Defining Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Is_laundering\", numTrees=100)\n",
    "\n",
    "# Creating pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+\n",
      "|Is_laundering|prediction|         probability|\n",
      "+-------------+----------+--------------------+\n",
      "|          0.0|       0.0|[0.88679275349344...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.96862865490560...|\n",
      "|          0.0|       0.0|[0.96862865490560...|\n",
      "|          0.0|       0.0|[0.56948556142227...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.93752777435884...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.94004278936793...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.56948556142227...|\n",
      "|          0.0|       0.0|[0.96202870477199...|\n",
      "|          0.0|       0.0|[0.94106618379789...|\n",
      "|          0.0|       1.0|[0.45212826573220...|\n",
      "|          0.0|       0.0|[0.94191246467544...|\n",
      "|          0.0|       0.0|[0.94191246467544...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "|          0.0|       0.0|[0.94362789924139...|\n",
      "+-------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Predictions\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Show results\n",
    "predictions.select(\"Is_laundering\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8911\n",
      "Precision: 0.9990\n",
      "Recall: 0.8911\n",
      "F1-score: 0.9414\n",
      "ROC-AUC: 0.9914\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"Is_laundering\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "# Precision\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Is_laundering\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "\n",
    "# Recall\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Is_laundering\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "# F1-score\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Is_laundering\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# AUC-ROC (for imbalanced data)\n",
    "roc_evaluator = BinaryClassificationEvaluator(labelCol=\"Is_laundering\", rawPredictionCol=\"probability\", metricName=\"areaUnderROC\")\n",
    "roc_auc = roc_evaluator.evaluate(predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1_score:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**: 0.8911 — This means that the model correctly classified 89.11% of all instances. While not perfect, it is relatively high.</br>\n",
    "\n",
    "**Precision**: 0.9990 — This is a very strong score, meaning that when the model predicts a positive (fraudulent transaction), it is almost always correct. This is crucial in fraud detection, as false positives are costly. </br>\n",
    "\n",
    "**Recall**: 0.8911 — This is also fairly high, indicating that the model is good at identifying fraudulent transactions. However, it is lower than precision, meaning there might be some false negatives (fraudulent transactions missed by the model).</br>\n",
    "\n",
    "**F1-score**: 0.9414 — The F1-score is the harmonic mean of precision and recall, and it's high, which suggests that the model has a good balance between precision and recall. </br>\n",
    "\n",
    "**ROC-AUC**: 0.9914 — The ROC-AUC score close to 1.0 indicates that the model has an excellent ability to discriminate between the positive and negative classes (fraud and non-fraud). </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location',\n",
    "                    'Receiver_bank_location', 'Payment_type', 'Laundering_type']\n",
    "numeric_cols = ['Sender_account', 'Receiver_account', 'Amount', 'year', 'month', 'day', 'hour', 'minute', 'second','Is_laundering']\n",
    "scaled_cols = ['Amount', 'year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "\n",
    "# String Indexing for categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "\n",
    "# Casting numeric columns to double\n",
    "train_df = train_df.select([col(c).cast(\"double\").alias(c) for c in numeric_cols] + categorical_cols)\n",
    "test_df = test_df.select([col(c).cast(\"double\").alias(c) for c in numeric_cols] + categorical_cols)\n",
    "\n",
    "# Handling class imbalance using oversampling\n",
    "fraud_cases = train_df.filter(col(\"Is_laundering\") == 1)\n",
    "non_fraud_cases = train_df.filter(col(\"Is_laundering\") == 0)\n",
    "fraud_count = fraud_cases.count()\n",
    "non_fraud_count = non_fraud_cases.count()\n",
    "\n",
    "if fraud_count < non_fraud_count:\n",
    "    fraud_cases = fraud_cases.sample(withReplacement=True, fraction=non_fraud_count / fraud_count, seed=42)\n",
    "elif non_fraud_count < fraud_count:\n",
    "    non_fraud_cases = non_fraud_cases.sample(withReplacement=True, fraction=fraud_count / non_fraud_count, seed=42)\n",
    "\n",
    "# making class balance\n",
    "train_df = fraud_cases.union(non_fraud_cases)\n",
    "\n",
    "# Assemble features excluding 'Is_laundering'\n",
    "assembler = VectorAssembler(inputCols=[c for c in numeric_cols if c != 'Is_laundering'] + [c + \"_index\" for c in categorical_cols], outputCol=\"features\")\n",
    "\n",
    "# Scaling numeric columns\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Defining Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol=\"scaled_features\", labelCol=\"Is_laundering\")\n",
    "\n",
    "# Creating pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import random\n",
    "num_trees = random.choice([30, 50, 70]) \n",
    "max_depth = random.choice([5, 10, 15])  \n",
    "max_bins = random.choice([32, 64, 128])  \n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [num_trees])\n",
    "             .addGrid(rf.maxDepth, [max_depth])\n",
    "             .addGrid(rf.maxBins, [max_bins])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Is_laundering\")\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "cvModel = crossval.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model ROC-AUC:  0.9682567110290056\n"
     ]
    }
   ],
   "source": [
    "#best model\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Evaluating on the test data\n",
    "predictions = bestModel.transform(test_df)\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Best Model ROC-AUC: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 70\n",
      "Best maxDepth: 5\n",
      "Best maxBins: 128\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = bestModel.stages[-1]  \n",
    "best_numTrees = best_rf_model.getOrDefault('numTrees')\n",
    "best_maxDepth = best_rf_model.getOrDefault('maxDepth')\n",
    "best_maxBins = best_rf_model.getOrDefault('maxBins')\n",
    "\n",
    "print(f\"Best numTrees: {best_numTrees}\")\n",
    "print(f\"Best maxDepth: {best_maxDepth}\")\n",
    "print(f\"Best maxBins: {best_maxBins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
